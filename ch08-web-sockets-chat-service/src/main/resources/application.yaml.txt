# Override the port Tomcat listens on
server:
  port: 9073

eureka:
  client:
    serviceUrl:
      defaultZone: http://localhost:9070/eureka/

# Customize log levels
logging:
  level:
    reactor:
      core: TRACE
      util: TRACE
    org:
      springframework:
        data: TRACE
        cloud: DEBUG
        integration: DEBUG
    io:
      netty: DEBUG
      reactor: DEBUG
    com:
      giocosmiano: DEBUG

#
#  We need to express to Spring Cloud Stream that our source and sink need to
#  communicate through the same RabbitMQ exchange. To do so, we need to provide the following settings
#
#  spring.cloud.stream.bindings is configured for both the input and the output channel's destination to be
#  learning-spring-boot. When using RabbitMQ bindings, this is the name of the exchange and Spring
#  Cloud Stream uses topic exchanges by default
#
#  We take advantage of Spring Cloud Streams' support for consumer groups by also setting the group
#  property. This ensures that even if there are multiple stream listeners to a given channel, only one
#  listener will consume any one message. This type of guarantee is required in cloud-native
#  environments when we can expect to run multiple instances
#
#  The logical name for a microservice used by Eureka and Ribbon is set using spring.application.name
#
#  The logical name is case insensitive, so you can use either http://COMMENTS/comments/{imageId}
#  or http://comments/comments/{imageId}. Uppercase helps make it clear that this is a logical
#  hostname, not a physical one
#
#  With this in place, it doesn't matter where we deploy our system nor how many instances are running.
#  Eureka will dynamically update things, and also support multiple copies registered under the same
#  name. Ribbon will handle routing between all instances
#
#  NOTE: If you look closely, you can spot that the Eureka Server is running on Apache Tomcat. So
#  far, we've run everything on Netty, right? Since Eureka is a separate process not involved
#  in direct operations, it's okay for it not to be a Reactive Streams-based application
#
spring:
  application:
    name: images
  # To connect IDE to a remotely running application and push code changes over the wire, allowing to automatically make mods and test them immediately
  devtools:
    remote:
      secret: ch08-web-sockets-chat-service
    restart:
      poll-interval: 4000
  # Normally, when using RabbitMQ, each instance of comments will register its own queue, and
  # hence, receive its own copy of newly posted comments. This would result in double posting
  # in this scenario. However, Spring Cloud Stream has a solution--consumer groups. By
  # having spring.cloud.stream.bindings.input.group=comments in comments micro service's
  # application.yml , we declare that only one such queue should receive each individual
  # message. This ensures that only one of the micro services actually processes a given event
  cloud:
    stream:
      bindings:
        input:
          destination: learning-spring-boot
        output:
          destination: learning-spring-boot
          group: comment-service
          content-type: application/json

# http://localhost:9072/actuator
management:
  endpoints:
# exposing endpoints over http
    web:
      exposure:
        include: "*"
# exposing endpoints over jmx
#    jmx:
#      exposure:
#        include: "*"

